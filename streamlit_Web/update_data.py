# ==============================================================================
# update_data.py - ë°ì´í„° ìˆ˜ì§‘ ë° ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
# ==============================================================================
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ì™¸ë¶€ API(ê³µê³µë°ì´í„°í¬í„¸, ì¹´ì¹´ì˜¤)
# ë¡œë¶€í„° ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê°€ê³µí•œ í›„, MySQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ”
# ETL(Extract, Transform, Load) íŒŒì´í”„ë¼ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.
#
# [ì£¼ìš” ì‹¤í–‰ íë¦„]
# 1. **ì„¤ì • ë¡œë“œ:** `config.ini`ì—ì„œ API í‚¤ì™€ DB ì ‘ì† ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# 2. **ë°ì´í„° ì¶”ì¶œ (Extract):**
#    - `fetch_abandoned_animals`: ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ ìœ ê¸°ë™ë¬¼ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
#      (ìµœê·¼ 6ê°œì›” ì¹˜, ê°œ/ê³ ì–‘ì´)
#    - `fetch_shelters`: ì „êµ­ì˜ ëª¨ë“  ë™ë¬¼ë³´í˜¸ì†Œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
#    - `get_coordinates_from_address`: ì¹´ì¹´ì˜¤ ì§€ë„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì†Œë¥¼
#      ìœ„ë„/ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜(ì§€ì˜¤ì½”ë”©)í•©ë‹ˆë‹¤.
# 3. **ë°ì´í„° ë³€í™˜ (Transform):**
#    - `preprocess_data`: APIë¡œë¶€í„° ë°›ì€ ì›ë³¸(raw) ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ
#      ê°€ê³µí•©ë‹ˆë‹¤. (ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½, ë°ì´í„° íƒ€ì… ë³€í™˜, íŒŒìƒ ë³€ìˆ˜ ìƒì„± ë“±)
#    - ë™ë¬¼ ë°ì´í„°ì™€ ë³´í˜¸ì†Œ ë°ì´í„°ë¥¼ ê²°í•©í•˜ê³ , í•„ìš”í•œ ì •ë³´ë“¤ì„ ì§‘ê³„í•©ë‹ˆë‹¤.
# 4. **ë°ì´í„° ì ì¬ (Load):**
#    - `update_database`: ê°€ê³µëœ ë°ì´í„°ë¥¼ Pandas DataFrame í˜•íƒœë¡œ ë§Œë“  í›„,
#      SQLAlchemyë¥¼ í†µí•´ `shelters`ì™€ `animals` í…Œì´ë¸”ì— í•œ ë²ˆì— ë°€ì–´ ë„£ìŠµë‹ˆë‹¤.
#      (`if_exists='replace'` ì˜µì…˜ìœ¼ë¡œ ê¸°ì¡´ í…Œì´ë¸”ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.)
#
# [ì‹¤í–‰ ë°©ë²•]
# - í„°ë¯¸ë„ì—ì„œ `python update_data.py` ëª…ë ¹ìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤.
# - ì£¼ê¸°ì ìœ¼ë¡œ ìë™ ì‹¤í–‰ë˜ë„ë¡ ìŠ¤ì¼€ì¤„ë§(ì˜ˆ: Cron, Windows Scheduler)í•˜ì—¬
#   ë°ì´í„°ë¥¼ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ==============================================================================

import pandas as pd
import xml.etree.ElementTree as ET
import mysql.connector
from sqlalchemy import create_engine
import configparser
import os
from datetime import datetime, timedelta
import subprocess
import tempfile
from urllib.parse import quote
import requests
import json

# --- ê²½ë¡œ ì„¤ì • ---
current_script_path = os.path.abspath(__file__)
streamlit_web_dir = os.path.dirname(current_script_path)
project_root = os.path.dirname(streamlit_web_dir)
CONFIG_PATH = os.path.join(project_root, 'config.ini')

# --- ì„¤ì • ì •ë³´ ë¡œë“œ í•¨ìˆ˜ ---
def get_db_config():
    """`config.ini`ì—ì„œ [DB] ì„¹ì…˜ì˜ ì„¤ì •ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    config = configparser.ConfigParser()
    if not os.path.exists(CONFIG_PATH):
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CONFIG_PATH}")
    config.read(CONFIG_PATH)
    return config['DB']

def get_api_key():
    """`config.ini`ì—ì„œ ê³µê³µë°ì´í„°í¬í„¸ API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    config = configparser.ConfigParser()
    if not os.path.exists(CONFIG_PATH):
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CONFIG_PATH}")
    config.read(CONFIG_PATH)
    return config['API']['service_key']

def get_kakao_rest_api_key():
    """`config.ini`ì—ì„œ ì¹´ì¹´ì˜¤ ì§€ë„ API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    config = configparser.ConfigParser()
    if not os.path.exists(CONFIG_PATH):
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CONFIG_PATH}")
    config.read(CONFIG_PATH)
    return config['API']['kakao_rest_api_key']

def fetch_abandoned_animals(api_key, bgnde, endde, upkind=''):
    """ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ íŠ¹ì • ê¸°ê°„ê³¼ ì¶•ì¢…ì˜ ìœ ê¸°ë™ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    api_key_encoded = quote(api_key)
    endpoint = "https://apis.data.go.kr/1543061/abandonmentPublicService_v2/abandonmentPublic_v2"

    all_items = []
    page_no = 1
    num_of_rows = 1000 # APIê°€ í—ˆìš©í•˜ëŠ” ìµœëŒ€ ìš”ì²­ ê°œìˆ˜

    while True:
        # API ìš”ì²­ URL êµ¬ì„±
        url = f"{endpoint}?serviceKey={api_key_encoded}&bgnde={bgnde}&endde={endde}&pageNo={page_no}&numOfRows={num_of_rows}&_type=xml"
        if upkind:
            url += f"&upkind={upkind}"

        print(f"[DEBUG] API ìš”ì²­ URL: {url}")

        # PowerShellì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
        fp, temp_path = tempfile.mkstemp(suffix=".xml")
        os.close(fp)

        try:
            command = f"powershell -Command \"(New-Object System.Net.WebClient).DownloadFile('{url}', '{temp_path}')\""
            subprocess.run(command, check=True, shell=True, capture_output=True, text=True)

            with open(temp_path, 'rb') as f:
                xml_data = f.read()

            if not xml_data:
                print(f"ê²½ê³ : í˜ì´ì§€ {page_no}ì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                break

            root = ET.fromstring(xml_data.decode('utf-8'))

            # API ì‘ë‹µ ì½”ë“œ í™•ì¸
            result_code = root.findtext('.//resultCode', 'N/A')
            if result_code != '00':
                print(f"API ì˜¤ë¥˜ ë°œìƒ (ì½”ë“œ: {result_code}, ë©”ì‹œì§€: {root.findtext('.//resultMsg', 'N/A')})")
                break

            items_in_page = root.findall('.//item')
            if not items_in_page:
                print(f"ì •ë³´: í˜ì´ì§€ {page_no}ì— ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break

            # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            for item in items_in_page:
                item_dict = {child.tag: child.text for child in item}
                all_items.append(item_dict)

            total_count = int(root.findtext('.//totalCount', '0'))
            print(f"í˜ì´ì§€ {page_no}ì—ì„œ {len(items_in_page)}ê±´ ë°ì´í„° ìˆ˜ì§‘. (í˜„ì¬ê¹Œì§€ ì´ {len(all_items)} / ì „ì²´ {total_count}ê±´)")

            # ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©´ ë°˜ë³µ ì¢…ë£Œ
            if len(all_items) >= total_count:
                break

            page_no += 1

        except subprocess.CalledProcessError as e:
            print(f"PowerShellì„ í†µí•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e.stderr}")
            return None # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
        except ET.ParseError as e:
            print(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
        except Exception as e:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)

    return all_items

def _fetch_sido_list(api_key):
    """ë³´í˜¸ì†Œ ëª©ë¡ ì¡°íšŒë¥¼ ìœ„í•´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì‹œ/ë„ ëª©ë¡ ì¡°íšŒ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    api_key_encoded = quote(api_key)
    endpoint = "https://apis.data.go.kr/1543061/abandonmentPublicService_v2/sido_v2"
    url = f"{endpoint}?serviceKey={api_key_encoded}&numOfRows=100&_type=xml"
    
    fp, temp_path = tempfile.mkstemp(suffix=".xml")
    os.close(fp)
    
    try:
        command = f"powershell -Command \"(New-Object System.Net.WebClient).DownloadFile('{url}', '{temp_path}')\""
        subprocess.run(command, check=True, shell=True, capture_output=True, text=True)
        
        with open(temp_path, 'rb') as f:
            xml_data = f.read()
        
        if not xml_data:
            return []
            
        root = ET.fromstring(xml_data.decode('utf-8'))
        sido_list = []
        for item in root.findall('.//item'):
            sido_list.append({"code": item.findtext("orgCd"), "name": item.findtext("orgdownNm")})
        return sido_list
    except Exception as e:
        print(f"ì‹œ/ë„ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

def _fetch_sigungu_list(api_key, sido_code):
    """íŠ¹ì • ì‹œ/ë„ì— ì†í•œ ì‹œ/êµ°/êµ¬ ëª©ë¡ì„ ì¡°íšŒí•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    api_key_encoded = quote(api_key)
    endpoint = "https://apis.data.go.kr/1543061/abandonmentPublicService_v2/sigungu_v2"
    url = f"{endpoint}?serviceKey={api_key_encoded}&upr_cd={sido_code}&_type=xml"
    
    fp, temp_path = tempfile.mkstemp(suffix=".xml")
    os.close(fp)
    
    try:
        command = f"powershell -Command \"(New-Object System.Net.WebClient).DownloadFile('{url}', '{temp_path}')\""
        subprocess.run(command, check=True, shell=True, capture_output=True, text=True)
        
        with open(temp_path, 'rb') as f:
            xml_data = f.read()
        
        if not xml_data:
            return []
            
        root = ET.fromstring(xml_data.decode('utf-8'))
        sigungu_list = []
        for item in root.findall('.//item'):
            sigungu_list.append({"upr_code": item.findtext("uprCd"), "code": item.findtext("orgCd"), "name": item.findtext("orgdownNm")})
        return sigungu_list
    except Exception as e:
        print(f"ì‹œ/êµ°/êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

def fetch_shelters(api_key):
    """ì „êµ­ì˜ ëª¨ë“  ë™ë¬¼ë³´í˜¸ì†Œ ì •ë³´ë¥¼ ì‹œ/ë„ ë° ì‹œ/êµ°/êµ¬ë³„ë¡œ ìˆœíšŒí•˜ë©° ê°€ì ¸ì˜µë‹ˆë‹¤."""
    api_key_encoded = quote(api_key)
    endpoint = "https://apis.data.go.kr/1543061/abandonmentPublicService_v2/shelter_v2"
    all_shelters = []
    sido_list = _fetch_sido_list(api_key)

    if not sido_list:
        print("ê²½ê³ : ì‹œë„ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ì—¬ ë³´í˜¸ì†Œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    for sido_info in sido_list:
        sido_code = sido_info['code']
        sido_name = sido_info['name']
        print(f"--- {sido_name} ({sido_code}) ì§€ì—­ì˜ ì‹œ/êµ°/êµ¬ ëª©ë¡ ìˆ˜ì§‘ ---")
        sigungu_list = _fetch_sigungu_list(api_key, sido_code)

        # ì‹œ/êµ°/êµ¬ ëª©ë¡ì´ ì—†ëŠ” ê²½ìš° (e.g., ì„¸ì¢…ì‹œ), ì‹œ/ë„ ì½”ë“œë¥¼ ì‹œ/êµ°/êµ¬ ì½”ë“œë¡œ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì¡°íšŒ ì‹œë„
        if not sigungu_list:
            print(f"ì •ë³´: {sido_name}ì— í•˜ìœ„ ì‹œ/êµ°/êµ¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ì‹œ/ë„ ì½”ë“œë¡œ ì§ì ‘ ë³´í˜¸ì†Œ ì¡°íšŒë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
            sigungu_list = [{'upr_code': sido_code, 'code': sido_code, 'name': sido_name}]

        for sigungu_info in sigungu_list:
            sigungu_code = sigungu_info['code']
            sigungu_name = sigungu_info['name']
            print(f"--- {sido_name} > {sigungu_name} ë³´í˜¸ì†Œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ---")

            url = f"{endpoint}?serviceKey={api_key_encoded}&upr_cd={sido_code}&org_cd={sigungu_code}&_type=xml"
            print(f"[DEBUG] ë³´í˜¸ì†Œ API ìš”ì²­ URL: {url}")

            fp, temp_path = tempfile.mkstemp(suffix=".xml")
            os.close(fp)

            try:
                command = f"powershell -Command \"(New-Object System.Net.WebClient).DownloadFile('{url}', '{temp_path}')\""
                subprocess.run(command, check=True, shell=True, capture_output=True, text=True)

                with open(temp_path, 'rb') as f:
                    xml_data = f.read()

                if not xml_data:
                    continue

                root = ET.fromstring(xml_data.decode('utf-8'))
                result_code = root.findtext('.//resultCode', 'N/A')

                if result_code != '00':
                    if result_code != '03':
                         print(f"API ì˜¤ë¥˜ (ì½”ë“œ: {result_code}, ë©”ì‹œì§€: {root.findtext('.//resultMsg', 'N/A')})")
                    continue

                items_in_page = root.findall('.//item')
                for item in items_in_page:
                    item_dict = {child.tag: child.text for child in item}
                    all_shelters.append(item_dict)

            except Exception as e:
                print(f"{sigungu_name} ë³´í˜¸ì†Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            finally:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
    
    return all_shelters

    api_key_encoded = quote(api_key)
    endpoint = "https://apis.data.go.kr/1543061/abandonmentPublicService_v2/shelter_v2"
    all_shelters = []
    sido_list = _fetch_sido_list(api_key)

    if not sido_list:
        print("ê²½ê³ : ì‹œë„ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ì—¬ ë³´í˜¸ì†Œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    for sido_info in sido_list:
        sido_code = sido_info['code']
        sido_name = sido_info['name']
        print(f"--- {sido_name} ({sido_code}) ë³´í˜¸ì†Œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ---")

        page_no = 1
        collected_in_sido = 0
        total_in_sido = -1 # -1ë¡œ ì´ˆê¸°í™”í•˜ì—¬ ì•„ì§ totalCountë¥¼ ë°›ì§€ ì•Šì•˜ìŒì„ í‘œì‹œ

        while True:
            url = f"{endpoint}?serviceKey={api_key_encoded}&upr_cd={sido_code}&pageNo={page_no}&numOfRows=1000&_type=xml"
            print(f"[DEBUG] ë³´í˜¸ì†Œ API ìš”ì²­ URL: {url}") # ë””ë²„ê¹…ì„ ìœ„í•œ URL ì¶œë ¥

            fp, temp_path = tempfile.mkstemp(suffix=".xml")
            os.close(fp)

            try:
                command = f"powershell -Command \"(New-Object System.Net.WebClient).DownloadFile('{url}', '{temp_path}')\""
                subprocess.run(command, check=True, shell=True, capture_output=True, text=True)

                with open(temp_path, 'rb') as f:
                    xml_data = f.read()

                if not xml_data:
                    print(f"ê²½ê³ : {sido_name} í˜ì´ì§€ {page_no}ì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                    break

                root = ET.fromstring(xml_data.decode('utf-8'))
                result_code = root.findtext('.//resultCode', 'N/A')

                if result_code != '00':
                    print(f"API ì˜¤ë¥˜ (ì½”ë“œ: {result_code}, ë©”ì‹œì§€: {root.findtext('.//resultMsg', 'N/A')})")
                    break

                items_in_page = root.findall('.//item')
                if not items_in_page:
                    print(f"ì •ë³´: {sido_name} í˜ì´ì§€ {page_no}ì— ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break

                for item in items_in_page:
                    item_dict = {child.tag: child.text for child in item}
                    all_shelters.append(item_dict)
                
                collected_in_sido += len(items_in_page)

                if total_in_sido == -1: # ì²« ìš”ì²­ ì‹œì—ë§Œ totalCountë¥¼ ì„¤ì •
                    total_in_sido = int(root.findtext('.//totalCount', '0'))

                print(f"{sido_name} í˜ì´ì§€ {page_no}ì—ì„œ {len(items_in_page)}ê±´ ìˆ˜ì§‘. (í˜„ì¬ ì‹œ/ë„ ëˆ„ì  {collected_in_sido} / ì „ì²´ {total_in_sido}ê±´)")

                if collected_in_sido >= total_in_sido:
                    break
                
                page_no += 1

            except Exception as e:
                print(f"{sido_name} ë³´í˜¸ì†Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
            finally:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
    
    return all_shelters


def get_coordinates_from_address(address):
    """
    ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì£¼ì†Œ ë¬¸ìì—´ì„ ìœ„ë„, ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì§€ë„ ì‹œê°í™”ë¥¼ ìœ„í•´ í•„ìˆ˜ì ì¸ ê¸°ëŠ¥ì…ë‹ˆë‹¤.
    """
    kakao_api_key = get_kakao_rest_api_key()
    if not kakao_api_key:
        print("ì¹´ì¹´ì˜¤ REST API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None, None

    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {kakao_api_key}"}
    params = {"query": address}

    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status() # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        data = response.json()
        
        if data and data['documents']:
            coords = data['documents'][0]
            return float(coords['y']), float(coords['x']) # (ìœ„ë„, ê²½ë„) ìˆœì„œë¡œ ë°˜í™˜
        else:
            print(f"ì£¼ì†Œì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {address}")
            return None, None
    except requests.exceptions.RequestException as e:
        print(f"ì¹´ì¹´ì˜¤ ì§€ì˜¤ì½”ë”© API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None
    except json.JSONDecodeError:
        print(f"ì¹´ì¹´ì˜¤ ì§€ì˜¤ì½”ë”© API ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {response.text}")
        return None, None

def preprocess_data(animal_df_raw, shelter_api_df_raw):
    print(f"[DEBUG] preprocess_data ì‹œì‘. animal_df_raw íƒ€ì…: {type(animal_df_raw)}, shelter_api_df_raw íƒ€ì…: {type(shelter_api_df_raw)}")

    # -------------------------------------
    # 1. ë™ë¬¼ ë°ì´í„° ì²˜ë¦¬
    # -------------------------------------
    if isinstance(animal_df_raw, pd.DataFrame):
        animals_df = animal_df_raw.copy()
    else:
        animals_df = pd.DataFrame(animal_df_raw)

    if animals_df.empty:
        animals_df = pd.DataFrame()
        shelter_df_from_animals = pd.DataFrame()
    else:
        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½
        rename_map = {
            'desertionNo': 'desertion_no',
            'careNm': 'shelter_name',
            'age': 'age',
            'kindCd': 'species',
            'kindNm': 'kind_name',
            'specialMark': 'special_mark',
            'sexCd': 'sex',
            'noticeSdt': 'notice_date',
            'noticeNo': 'notice_no',
            'processState': 'process_state',
            'careAddr': 'care_addr',        # ì—¬ê¸° ì¤‘ìš”
            'careTel': 'care_tel',
            'colorCd': 'color',
            'weight': 'weight',
            'neuterYn': 'neuter',
            'happenPlace': 'happen_place',
            'upKindNm': 'upkind_name'
        }
        animals_df.rename(columns={k: v for k, v in rename_map.items() if k in animals_df.columns}, inplace=True)

        # ì´ë¯¸ì§€ URL
        if 'popfile1' in animals_df.columns:
            animals_df['image_url'] = animals_df['popfile1']
        elif 'popfile2' in animals_df.columns:
            animals_df['image_url'] = animals_df['popfile2']
        else:
            animals_df['image_url'] = None

        animals_df.drop(columns=['popfile1', 'popfile2'], errors='ignore', inplace=True)

        # ë‚ ì§œ ë³€í™˜
        if 'notice_date' in animals_df.columns:
            animals_df['notice_date'] = pd.to_datetime(animals_df['notice_date'], format='%Y%m%d', errors='coerce')

        # animal_name ìƒì„±
        if 'species' in animals_df.columns and 'sex' in animals_df.columns:
            animals_df['animal_name'] = animals_df['species'] + ' (' + animals_df['sex'] + ')'
        elif 'kind_name' in animals_df.columns:
            animals_df['animal_name'] = animals_df['kind_name']
        else:
            animals_df['animal_name'] = 'ì •ë³´ ì—†ìŒ'

        animals_df['personality'] = 'ì •ë³´ ì—†ìŒ'

        # ë³´í˜¸ì†Œ ì§‘ê³„
        agg_dict = {
            'care_addr_animal': ('care_addr', 'first'),
            'region': ('care_addr', lambda x: x.iloc[0].split()[0] if x.notna().any() else 'ì •ë³´ ì—†ìŒ'),
            'count': ('desertion_no', 'count'),
            'long_term': ('notice_date', lambda x: (x < pd.Timestamp.now() - pd.Timedelta(days=30)).sum()),
            'adopted': ('process_state', lambda x: (x == 'ì¢…ë£Œ(ì…ì–‘)').sum()),
            'species': ('species', lambda x: x.value_counts().index[0] if not x.empty else 'ì •ë³´ ì—†ìŒ'),
            'kind_name': ('kind_name', lambda x: x.value_counts().index[0] if not x.empty else 'ì •ë³´ ì—†ìŒ')
        }
        if 'image_url' in animals_df.columns:
            agg_dict['image_url'] = ('image_url', 'first')

        shelter_df_from_animals = animals_df.groupby('shelter_name').agg(**agg_dict).reset_index()

        if 'image_url' not in shelter_df_from_animals.columns:
            shelter_df_from_animals['image_url'] = None

    # -------------------------------------
    # 2. ë³´í˜¸ì†Œ ë°ì´í„° ì²˜ë¦¬
    # -------------------------------------
    if isinstance(shelter_api_df_raw, pd.DataFrame):
        shelter_api_df_processed = shelter_api_df_raw.copy()
    else:
        shelter_api_df_processed = pd.DataFrame(shelter_api_df_raw)

    if not shelter_api_df_processed.empty:
        rename_cols = {
            'careNm': 'shelter_name',
            'careRegNo': 'care_reg_no',
            'careAddr': 'care_addr_api',
            'careTel': 'care_tel',
            'dataStdDt': 'data_std_dt',
            'lat': 'lat_api',
            'lon': 'lon_api'
        }
        shelter_api_df_processed.rename(columns={k: v for k, v in rename_cols.items() if k in shelter_api_df_processed.columns}, inplace=True)

        shelter_api_df_processed['lat_api'] = pd.to_numeric(shelter_api_df_processed.get('lat_api', pd.NA), errors='coerce')
        shelter_api_df_processed['lon_api'] = pd.to_numeric(shelter_api_df_processed.get('lon_api', pd.NA), errors='coerce')
    else:
        shelter_api_df_processed = pd.DataFrame()

    # -------------------------------------
    # 3. ë°ì´í„° ë³‘í•©
    # -------------------------------------
    if shelter_df_from_animals.empty:
        merged_shelter_df = shelter_api_df_processed
    elif shelter_api_df_processed.empty:
        merged_shelter_df = shelter_df_from_animals
    else:
        merged_shelter_df = pd.merge(shelter_df_from_animals, shelter_api_df_processed, on='shelter_name', how='outer')

    if not merged_shelter_df.empty:
        care_addr_api = merged_shelter_df['care_addr_api'] if 'care_addr_api' in merged_shelter_df.columns else pd.Series(index=merged_shelter_df.index)
        care_addr_animal = merged_shelter_df['care_addr_animal'] if 'care_addr_animal' in merged_shelter_df.columns else pd.Series(index=merged_shelter_df.index)
        merged_shelter_df['care_addr'] = care_addr_api.fillna(care_addr_animal)

        # ì¢Œí‘œ
        merged_shelter_df['lat'] = merged_shelter_df['lat_api'] if 'lat_api' in merged_shelter_df.columns else pd.NA
        merged_shelter_df['lon'] = merged_shelter_df['lon_api'] if 'lon_api' in merged_shelter_df.columns else pd.NA

        # ì£¼ì†Œ ì¢Œí‘œ ìºì‹±
        cache = {}
        unique_addresses = merged_shelter_df.loc[
            merged_shelter_df['care_addr'].notna() &
            (merged_shelter_df['lat'].isna() | merged_shelter_df['lon'].isna()),
            'care_addr'
        ].unique()

        for addr in unique_addresses:
            if addr not in cache:
                lat, lon = get_coordinates_from_address(addr)
                cache[addr] = (lat, lon)

        for index, row in merged_shelter_df.iterrows():
            if pd.isna(row['lat']) or pd.isna(row['lon']):
                addr = row['care_addr']
                if addr in cache:
                    merged_shelter_df.at[index, 'lat'], merged_shelter_df.at[index, 'lon'] = cache[addr]

        merged_shelter_df['lat'] = merged_shelter_df['lat'].fillna(0)
        merged_shelter_df['lon'] = merged_shelter_df['lon'].fillna(0)

        merged_shelter_df.drop(columns=['care_addr_api', 'care_addr_animal', 'lat_api', 'lon_api'], inplace=True, errors='ignore')

        # ì¤‘ë³µ í™•ì¸ìš© ì¶œë ¥
        before_count = len(merged_shelter_df)
        duplicate_count = merged_shelter_df.duplicated(subset=['shelter_name']).sum()
        print(f"[DEBUG] ì¤‘ë³µ ì œê±° ì „ ë³´í˜¸ì†Œ ê°œìˆ˜: {before_count} (ì¤‘ë³µ {duplicate_count}ê°œ)")

        # ë³´í˜¸ì†Œ ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        merged_shelter_df.drop_duplicates(subset=['shelter_name'], inplace=True)

        after_count = len(merged_shelter_df)
        print(f"[DEBUG] ì¤‘ë³µ ì œê±° í›„ ë³´í˜¸ì†Œ ê°œìˆ˜: {after_count}")

    # -------------------------------------
    # 4. ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬
    # -------------------------------------
    if 'image_url' not in animals_df.columns:
        animals_df['image_url'] = None

    final_animal_cols = [
        'desertion_no', 'shelter_name', 'animal_name', 'species', 'kind_name', 'age',
        'upkind_name', 'image_url', 'personality', 'special_mark', 'notice_date', 'notice_no',
        'sex', 'neuter', 'color', 'weight', 'care_tel', 'care_addr', 
        'happen_place', 
        'process_state' 
    ]
    existing_final_cols = [col for col in final_animal_cols if col in animals_df.columns]

    return merged_shelter_df, animals_df[existing_final_cols]

# --- ë°ì´í„° ì ì¬ (Load) í•¨ìˆ˜ ---
def update_database(shelter_df, animal_df):
    """
    ê°€ê³µëœ ë°ì´í„°í”„ë ˆì„ì„ ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
    `if_exists='replace'` ì˜µì…˜ì€ ê¸°ì¡´ í…Œì´ë¸”ì´ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë§Œë“¤ê¸° ë•Œë¬¸ì—,
    í•­ìƒ ìµœì‹  ë°ì´í„°ë§Œ ìœ ì§€ë©ë‹ˆë‹¤.
    """
    if shelter_df.empty or animal_df.empty:
        print("ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    try:
        db_config = get_db_config()
        engine = create_engine(f"mysql+mysqlconnector://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}")
        
        with engine.connect() as conn:
            # to_sql ë©”ì†Œë“œëŠ” DataFrameì„ SQL í…Œì´ë¸”ë¡œ ë§¤ìš° í¸ë¦¬í•˜ê²Œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.
            shelter_df.to_sql('shelters', conn, if_exists='replace', index=False)
            animal_df.to_sql('animals', conn, if_exists='replace', index=False)
        print("ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì„±ê³µ!")
    except Exception as e:
        print(f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {e}")

# --- ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---
# ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ ì•„ë˜ ì½”ë“œê°€ ë™ì‘í•©ë‹ˆë‹¤.
if __name__ == "__main__":
    print("ì‹¤ì œ ë°ì´í„°ë¡œ DB ì—…ë°ì´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        API_KEY = get_api_key()
        if not API_KEY or 'YOUR_API_KEY' in API_KEY:
            print("!!! ê²½ê³ : config.ini íŒŒì¼ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            bgnde_str = '20250501'
            endde_str = '20250802'

            # ë™ë¬¼ ë°ì´í„° ìˆ˜ì§‘ (ê°œ, ê³ ì–‘ì´, ê¸°íƒ€)
            animal_types = {'ê°œ': '417000', 'ê³ ì–‘ì´': '422400', 'ê¸°íƒ€': '429900'}
            all_animals_data = []

            for animal_name, animal_code in animal_types.items():
                print(f"--- {animal_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ê¸°ê°„: {bgnde_str} ~ {endde_str}) ---")
                items = fetch_abandoned_animals(API_KEY, bgnde_str, endde_str, upkind=animal_code)
                if isinstance(items, list):
                    all_animals_data.extend(items)
                    print(f"ì„±ê³µ: {animal_name} ë°ì´í„° {len(items)}ê±´ ìˆ˜ì§‘")
                else:
                    print(f"ê²½ê³ : {animal_name} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # ğŸŸ¢ ì¤‘ë³µ ì œê±° (desertionNo ê¸°ì¤€)
            print("ì¤‘ë³µ ì œê±° ì¤‘...")
            unique_animals = {
                item.get('desertionNo'): item for item in all_animals_data
            }
            all_animals_data = list(unique_animals.values())
            print(f"ì¤‘ë³µ ì œê±° í›„ ì´ {len(all_animals_data)}ê±´ ë‚¨ìŒ")

            # ë³´í˜¸ì†Œ ë°ì´í„° ìˆ˜ì§‘
            print("--- ë³´í˜¸ì†Œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ---")
            all_shelters_data = fetch_shelters(API_KEY)
            if not isinstance(all_shelters_data, list):
                print("ê²½ê³ : ë³´í˜¸ì†Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                all_shelters_data = []

            # ì „ì²˜ë¦¬ ë° DB ì—…ë°ì´íŠ¸
            if all_animals_data or all_shelters_data:
                raw_animal_df = pd.DataFrame(all_animals_data)
                raw_shelter_api_df = pd.DataFrame(all_shelters_data)

                if not raw_animal_df.empty or not raw_shelter_api_df.empty:
                    print("ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                    shelters, animals = preprocess_data(raw_animal_df, raw_shelter_api_df)

                    print("ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                    update_database(shelters, animals)
                else:
                    print("APIì—ì„œ ìˆ˜ì§‘ëœ ë™ë¬¼ ë° ë³´í˜¸ì†Œ ë°ì´í„°ê°€ ì—†ì–´ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    except FileNotFoundError as e:
        print(e)
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")